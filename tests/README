# 🧪 Sistema de Testing del Trading Bot

Guía completa para ejecutar y crear tests de integración para el trading bot.

---

## 📋 Tabla de Contenidos

1. [Instalación](#instalación)
2. [Ejecutar Tests](#ejecutar-tests)
3. [Tipos de Tests](#tipos-de-tests)
4. [Cobertura de Tests](#cobertura-de-tests)
5. [Escribir Nuevos Tests](#escribir-nuevos-tests)
6. [CI/CD](#cicd)

---

## 🚀 Instalación

### Prerrequisitos

```bash
# Python 3.9+
python --version

# PostgreSQL corriendo (para tests de integración)
docker-compose up -d postgres
```

### Instalar Dependencias

```bash
# Instalar todas las dependencias (incluyendo testing)
pip install -r requirements.txt

# O instalar solo las de testing
pip install pytest pytest-flask pytest-cov pytest-mock
```

### Verificar Instalación

```bash
pytest --version
# pytest 7.4.3
```

---

## ▶️ Ejecutar Tests

### Métodos Disponibles

#### **1. Script Python (Recomendado)**

El script `run_tests.py` facilita ejecutar diferentes tipos de tests:

```bash
# Todos los tests
python run_tests.py

# Solo tests rápidos
python run_tests.py fast

# Solo tests de integración
python run_tests.py integration

# Solo tests del dashboard
python run_tests.py dashboard

# Con coverage
python run_tests.py --cov

# Con reporte HTML
python run_tests.py --cov --html

# Modo verbose
python run_tests.py -v

# Ver prints de los tests
python run_tests.py -s

# Tests específicos
python run_tests.py -k "test_api_account"

# Solo tests que fallaron antes
python run_tests.py --failed
```

#### **2. Pytest Directamente**

```bash
# Todos los tests
pytest tests/

# Tests específicos
pytest tests/test_dashboard_integration.py

# Una función específica
pytest tests/test_dashboard_integration.py::test_api_account

# Con verbose
pytest tests/ -v

# Con prints
pytest tests/ -s

# Por markers
pytest -m integration  # Solo integración
pytest -m "not slow"   # Excluir lentos
```

#### **3. Tests por Categoría**

```bash
# Tests unitarios (rápidos)
pytest -m unit

# Tests de integración (requieren BD)
pytest -m integration

# Tests del dashboard
pytest -m dashboard

# Tests de API
pytest -m api

# Solo tests rápidos
pytest -m "not slow"

# Solo tests lentos
pytest -m slow
```

---

## 🏷️ Tipos de Tests

### **Dashboard Integration Tests** (`test_dashboard_integration.py`)

Prueba todos los endpoints del dashboard:

| Test | Descripción | Requiere |
|------|-------------|----------|
| `test_index_page` | Página principal carga | - |
| `test_api_account` | Info de cuenta | API |
| `test_api_positions` | Posiciones abiertas | API |
| `test_api_config` | Configuración | - |
| `test_api_status` | Estado del bot | - |
| `test_api_trades_history` | Historial de trades | BD |
| `test_api_trades_stats` | Estadísticas | BD |
| `test_api_export_trades_csv` | Export CSV | BD |
| `test_api_export_trades_excel` | Export Excel | BD |
| `test_api_export_full_report` | Reporte completo | BD |
| `test_api_sessions_list` | Listar sesiones | BD |
| `test_api_session_detail` | Detalle sesión | BD |
| `test_api_backtest_run` | Ejecutar backtest | API |
| `test_api_signals_recent` | Señales recientes | BD |
| `test_api_health` | Health check | - |

### **Markers Disponibles**

```python
@pytest.mark.unit          # Tests unitarios rápidos
@pytest.mark.integration   # Tests de integración
@pytest.mark.dashboard     # Tests del dashboard
@pytest.mark.api          # Tests que requieren API
@pytest.mark.slow         # Tests lentos (>5s)
```

---

## 📊 Cobertura de Tests

### Generar Reporte de Coverage

```bash
# Ejecutar con coverage
pytest --cov=. --cov-report=html tests/

# O usar el script
python run_tests.py --cov --html
```

### Ver Reporte HTML

```bash
# Windows
start htmlcov/index.html

# Mac/Linux
open htmlcov/index.html

# O navegar manualmente a:
# file:///path/to/project/htmlcov/index.html
```

### Métricas de Coverage

El reporte muestra:
- **Líneas totales** en cada archivo
- **Líneas ejecutadas** durante los tests
- **Líneas no cubiertas** (falta testear)
- **% Coverage** por archivo

**Meta: >80% coverage en módulos críticos**

---

## ✍️ Escribir Nuevos Tests

### Estructura de un Test

```python
import pytest

def test_nombre_descriptivo(client, db_manager):
    """
    Descripción clara de qué se está probando
    """
    # Arrange - Preparar datos
    session_id = db_manager.start_session(10000.0, {})
    
    # Act - Ejecutar acción
    response = client.get('/api/endpoint')
    data = response.json()
    
    # Assert - Verificar resultado
    assert response.status_code == 200
    assert 'key' in data
    assert data['value'] > 0
```

### Usar Fixtures

```python
def test_with_fixtures(test_session, test_trades):
    """
    Fixtures disponibles:
    - client: Cliente Flask
    - db_manager: DatabaseManager
    - test_session: Sesión de prueba creada
    - test_trades: Trades de prueba
    - test_signals: Señales de prueba
    - mock_api_client: Mock de API
    """
    # Tu código aquí
    pass
```

### Ejemplo Completo

```python
import pytest

@pytest.mark.integration
@pytest.mark.dashboard
def test_export_trades_with_session(client, test_session, test_trades):
    """
    Test: Exportar trades de una sesión específica a CSV
    
    Given: Una sesión con 5 trades
    When: Se solicita exportar a CSV
    Then: Se descarga un archivo CSV válido
    """
    # Act
    response = client.get(f'/api/trades/export/csv?session_id={test_session}')
    
    # Assert
    assert response.status_code == 200
    assert 'text/csv' in response.content_type or 'application/octet-stream' in response.content_type
    
    # Verificar que el contenido tiene datos
    content = response.data.decode('utf-8')
    assert 'epic' in content.lower()
    assert 'pnl' in content.lower()
```

### Tests Parametrizados

```python
@pytest.mark.parametrize('endpoint,expected_keys', [
    ('/api/account', ['balance', 'available']),
    ('/api/config', ['assets', 'max_positions']),
    ('/api/status', ['status', 'is_trading_hours'])
])
def test_endpoints_have_required_keys(client, endpoint, expected_keys):
    """Test que múltiples endpoints devuelven las keys correctas"""
    response = client.get(endpoint)
    
    if response.status_code == 200:
        data = response.json()
        for key in expected_keys:
            assert key in data
```

---

## 🎯 Mejores Prácticas

### ✅ DO (Hacer)

- **Nombres descriptivos**: `test_export_trades_returns_csv_file`
- **Tests independientes**: Cada test debe poder ejecutarse solo
- **Usar fixtures**: Reutilizar configuración común
- **Limpiar después**: Usar `yield` en fixtures
- **Documentar**: Docstring explicando el propósito
- **Asserts claros**: Mensajes descriptivos
- **Fast first**: Tests unitarios rápidos primero

### ❌ DON'T (No hacer)

- Tests dependientes entre sí
- Hardcodear valores (usar fixtures/config)
- Tests sin asserts
- Ignorar tests que fallan
- Tests muy complejos (dividir en varios)
- Modificar BD de producción

---

## 🔧 Troubleshooting

### Problema: Tests fallan por BD

```bash
# Verificar que PostgreSQL está corriendo
docker ps | grep postgres

# Iniciar PostgreSQL
docker-compose up -d postgres

# Verificar conexión
python -c "from database.connection import DatabaseConnection; db = DatabaseConnection(); print('✅ Connected')"
```

### Problema: Tests fallan por API

Los tests de API pueden fallar si:
- No hay conexión a internet
- Credenciales inválidas
- API de Capital.com caída

**Solución:** Usar `mock_api_client` fixture

```python
def test_with_mock_api(mock_api_client):
    """Test sin conexión real a API"""
    account = mock_api_client.get_account_info()
    assert account['balance']['balance'] == 10000.0
```

### Problema: Imports no funcionan

```bash
# Verificar que el proyecto está en PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# O ejecutar desde raíz del proyecto
cd /path/to/trading_bot
pytest tests/
```

---

## 🚦 CI/CD

### GitHub Actions Example

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Run tests
        run: |
          python run_tests.py --cov
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

---

## 📚 Recursos

- [Pytest Documentation](https://docs.pytest.org/)
- [Flask Testing](https://flask.palletsprojects.com/en/3.0.x/testing/)
- [Coverage.py](https://coverage.readthedocs.io/)

---

## 🆘 Ayuda

Si tienes problemas con los tests:

1. Verifica que todas las dependencias estén instaladas
2. Asegúrate de que PostgreSQL está corriendo
3. Ejecuta tests en modo verbose: `pytest -vv`
4. Revisa los logs: `pytest -s`
5. Ejecuta un test individual para debugging

---

**¿Preguntas?** Revisa la documentación o abre un issue en el proyecto.